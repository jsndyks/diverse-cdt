@inproceedings{mccurdy_action_2016,
	title        = {Action design research and visualization design},
	shorttitle   = {https://openaccess.city.ac.uk/id/eprint/15270/},
	author       = {McCurdy, Nina and Dykes, Jason and Meyer, Miriah},
	year         = 2016,
	booktitle    = {Proceedings of the {Sixth} {Workshop} on {Beyond} {Time} and {Errors} on {Novel} {Evaluation} {Methods} for {Visualization}},
	publisher    = {ACM},
	pages        = {10--18},
	url          = {https://dl.acm.org/doi/pdf/10.1145/2993901.2993916}
}
@inproceedings{lo_rejecting_nodate,
	title        = {Rejecting {Colonial} {Practices} in {Data} {Storytelling}},
	author       = {Lo, Peiying and Said, Nabilah and Griselda, Gabriele and Mansoor, Munirah and Zein, Zafirah and Teo, Amanda},
	url          = {https://www.zotero.org/groups/6278359/diverse-cdt_datavis_research/items/VEK3AU2K/reader}
}
@inproceedings{wood_beyond_2022,
	title        = {Beyond the {Walled} {Garden}.},
	author       = {Wood, Jo},
	year         = 2022,
	booktitle    = {alt.{VIS} - 2022},
	publisher    = {IEEE},
	address      = {Oklahoma City, OK},
	url          = {https://altvis.github.io/papers/2022/walled-garden.pdf}
}
@article{kerzner_framework_2018,
	title        = {A framework for creative visualization-opportunities workshops},
	author       = {Kerzner, Ethan and Goodwin, Sarah and Dykes, Jason and Jones, Sara and Meyer, Miriah},
	year         = 2018,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 25,
	number       = 1,
	pages        = {748--758},
	url          = {https://arxiv.org/pdf/1808.02502}
}
@article{goodwin_creative_2013,
	title        = {Creative user-centered visualization design for energy analysts and modelers},
	author       = {Goodwin, Sarah and Dykes, Jason and Jones, Sara and Dillingham, Iain and Dove, Graham and Duffy, Alison and Kachkaev, Alexander and Slingsby, Aidan and Wood, Jo},
	year         = 2013,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 19,
	number       = 12,
	pages        = {2516--2525},
	url          = {https://openaccess.city.ac.uk/id/eprint/2618/5/Goodwin-preprint.pdf}
}
@article{hall_design_2019,
	title        = {Design by {Immersion}: {A} transdisciplinary approach to problem-driven visualizations},
	author       = {Hall, Kyle Wm and Bradley, Adam J and Hinrichs, Uta and Huron, Samuel and Wood, Jo and Collins, Christopher and Carpendale, Sheelagh},
	year         = 2019,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 26,
	number       = 1,
	pages        = {109--118},
	url          = {https://arxiv.org/pdf/1908.00559}
}
@inproceedings{rijken_illegible_2021,
	title        = {Illegible semantics: {Exploring} the design space of metal logos},
	shorttitle   = {https://noeska.github.io/illegiblesemantics/},
	author       = {Rijken, Gerrit J and Cutura, Rene and Heyen, Frank and Sedlmair, Michael and Correll, Michael and Dykes, Jason and Smit, Noeska},
	year         = 2021,
	booktitle    = {{arXiv} preprint {arXiv}:2109.01688},
	publisher    = {IEEE},
	address      = {New Orleans, LA},
	url          = {https://arxiv.org/pdf/2109.01688}
}
@inproceedings{varona_theory_2025,
	title        = {Theory is {Shapes}},
	author       = {Varona, Matthew and Hedayati, Maryam and Kay, Matthew and Nobre, Carolina},
	year         = 2025,
	booktitle    = {{arXiv} preprint {arXiv}:2510.01382},
	address      = {Vienna, Austria},
	url          = {https://altvis.github.io/#theory-is-shapes}
}
@inproceedings{shneiderman_strategies_2006,
	title        = {Strategies for evaluating information visualization tools: multi-dimensional in-depth long-term case studies},
	shorttitle   = {Strategies for evaluating information visualization tools},
	author       = {Shneiderman, Ben and Plaisant, Catherine},
	year         = 2006,
	month        = may,
	booktitle    = {Proceedings of the 2006 {AVI} workshop on {BEyond} time and errors: novel evaluation methods for information visualization},
	publisher    = {ACM},
	address      = {Venice Italy},
	pages        = {1--7},
	doi          = {10.1145/1168149.1168158},
	isbn         = {978-1-59593-562-5},
	url          = {https://dl.acm.org/doi/10.1145/1168149.1168158},
	urldate      = {2025-11-20},
	abstract     = {After an historical review of evaluation methods, we describe an emerging research method called Multi-dimensional In-depth Long-term Case studies (MILCs) which seems well adapted to study the creative activities that users of information visualization systems engage in. We propose that the efficacy of tools can be assessed by documenting 1) usage (observations, interviews, surveys, logging etc.) and 2) expert users’ success in achieving their professional goals. We summarize lessons from related ethnography methods used in HCI and provide guidelines for conducting MILCs for information visualization. We suggest ways to refine the methods for MILCs in modest sized projects and then envision ambitious projects with 3-10 researchers working over 1-3 years to understand individual and organizational use of information visualization by domain experts working at the frontiers of knowledge in their fields.},
	language     = {en}
}
@article{sedlmair_design_2012,
	title        = {Design {Study} {Methodology}: {Reflections} from the {Trenches} and the {Stacks}},
	shorttitle   = {Design {Study} {Methodology}},
	author       = {Sedlmair, Michael and Meyer, Miriah and Munzner, Tamara},
	year         = 2012,
	month        = dec,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 18,
	number       = 12,
	pages        = {2431--2440},
	doi          = {10.1109/TVCG.2012.213},
	issn         = {1077-2626},
	url          = {http://ieeexplore.ieee.org/document/6327248/},
	urldate      = {2025-11-19},
	copyright    = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	abstract     = {Design studies are an increasingly popular form of problem-driven visualization research, yet there is little guidance available about how to do them effectively. In this paper we reﬂect on our combined experience of conducting twenty-one design studies, as well as reading and reviewing many more, and on an extensive literature review of other ﬁeld work methods and methodologies. Based on this foundation we provide deﬁnitions, propose a methodological framework, and provide practical guidance for conducting design studies. We deﬁne a design study as a project in which visualization researchers analyze a speciﬁc real-world problem faced by domain experts, design a visualization system that supports solving this problem, validate the design, and reﬂect about lessons learned in order to reﬁne visualization design guidelines. We characterize two axes—a task clarity axis from fuzzy to crisp and an information location axis from the domain expert’s head to the computer—and use these axes to reason about design study contributions, their suitability, and uniqueness from other approaches. The proposed methodological framework consists of 9 stages: learn, winnow, cast, discover, design, implement, deploy, reﬂect, and write. For each stage we provide practical guidance and outline potential pitfalls. We also conducted an extensive literature survey of related methodological approaches that involve a signiﬁcant amount of qualitative ﬁeld work, and compare design study methodology to that of ethnography, grounded theory, and action research.},
	language     = {en}
}
@inproceedings{mccurdy_rhymedesign_2015,
	title        = {{RhymeDesign}: {A} {Tool} for {Analyzing} {Sonic} {Devices} in {Poetry}},
	shorttitle   = {{RhymeDesign}},
	author       = {McCurdy, Nina and Srikumar, Vivek and Meyer, Miriah},
	year         = 2015,
	booktitle    = {Proceedings of the {Fourth} {Workshop} on {Computational} {Linguistics} for {Literature}},
	publisher    = {Association for Computational Linguistics},
	address      = {Denver, Colorado, USA},
	pages        = {12--22},
	doi          = {10.3115/v1/W15-0702},
	url          = {http://aclweb.org/anthology/W15-0702},
	urldate      = {2025-11-20},
	abstract     = {The analysis of sound and sonic devices in poetry is the focus of much poetic scholarship, and poetry scholars are becoming increasingly interested in the role that computation might play in their research. Since the nature of such sonic analysis is unique, the associated tasks are not supported by standard text analysis techniques. We introduce a formalism for analyzing sonic devices in poetry. In addition, we present RhymeDesign, an open-source implementation of our formalism, through which poets and poetry scholars can explore their individual notion of rhyme.},
	language     = {en}
}
@inproceedings{jones_use_2008,
	title        = {Use and {Influence} of {Creative} {Ideas} and {Requirements} for a {Work}-{Integrated} {Learning} {System}},
	author       = {Jones, Sara and Lynch, Perry and Maiden, Neil and Lindstaedt, Stefanie},
	year         = 2008,
	month        = sep,
	booktitle    = {2008 16th {IEEE} {International} {Requirements} {Engineering} {Conference}},
	publisher    = {IEEE},
	address      = {Barcelona, Spain},
	pages        = {289--294},
	doi          = {10.1109/RE.2008.54},
	isbn         = {978-0-7695-3309-4},
	url          = {http://ieeexplore.ieee.org/document/4685684/},
	urldate      = {2025-11-19}
}
@article{pagani_unlocking_2025,
	title        = {Unlocking {Marketing} {Creativity} {Using} {Artificial} {Intelligence}},
	author       = {Pagani, Margherita and Wind, Yoram},
	year         = 2025,
	journal      = {Journal of Interactive Marketing},
	volume       = 60,
	number       = 1,
	pages        = {1--24},
	doi          = {10.1177/10949968241265855},
	url          = {https://doi.org/10.1177/10949968241265855},
	note         = {\_eprint: https://doi.org/10.1177/10949968241265855},
	abstract     = {This article examines the role of artificial intelligence (AI) in enhancing marketing creativity by analyzing the synergy between computational and human creative processes. Through two studies, the authors investigate nongenerative and generative AI applications within marketing contexts using a conceptually driven and empirically derived approach. In Study 1, the authors observe how creative individuals, particularly artists, utilize AI and its effects on their creative experiences, revealing AI's role as (1) a new instrumental resource, (2) a tool for exploring possibilities, and (3) a means to deconstruct the creative process. Study 2 assesses 1,036 AI systems (2015–2021) and 241,292 AI models (2022–2024), categorizing them into four clusters and three levels of observed creativity. From these insights, the authors introduce a framework for AI-enabled creativity: (1) inspiring agile methods, (2) augmenting human creativity, and (3) inspiring unconventional thinking. Validated by three workshops, this framework equips marketing leaders with a deeper comprehension of AI's creative potential. The authors advocate for AI integration within agile, augmented, and unconventional marketing approaches, advancing our understanding of AI's contribution to marketing creativity. Additionally, they propose a research roadmap for empirical validation in real-world applications.}
}
@misc{dellacqua_cybernetic_2025,
	title        = {The {Cybernetic} {Teammate}: {A} {Field} {Experiment} on {Generative} {AI} {Reshaping} {Teamwork} and {Expertise}},
	shorttitle   = {The {Cybernetic} {Teammate}},
	author       = {Dell'Acqua, Fabrizio and Ayoubi, Charles and Lifshitz-Assaf, Hila and Sadun, Raffaella and Mollick, Ethan R. and Mollick, Lilach and Han, Yi and Goldman, Jeff and Nair, Hari and Taub, Stew and Lakhani, Karim R.},
	year         = 2025,
	publisher    = {SSRN},
	doi          = {10.2139/ssrn.5188231},
	url          = {https://www.ssrn.com/abstract=5188231},
	urldate      = {2025-11-19}
}
@inproceedings{de_rooij_emotion_2015,
	title        = {Emotion and {Creativity}: {Hacking} into {Cognitive} {Appraisal} {Processes} to {Augment} {Creative} {Ideation}},
	shorttitle   = {Emotion and {Creativity}},
	author       = {De Rooij, Alwin and Corr, Philip J. and Jones, Sara},
	year         = 2015,
	month        = jun,
	booktitle    = {Proceedings of the 2015 {ACM} {SIGCHI} {Conference} on {Creativity} and {Cognition}},
	publisher    = {ACM},
	address      = {Glasgow United Kingdom},
	pages        = {265--274},
	doi          = {10.1145/2757226.2757227},
	isbn         = {978-1-4503-3598-0},
	url          = {https://dl.acm.org/doi/10.1145/2757226.2757227},
	urldate      = {2025-11-19},
	language     = {en}
}
@article{boucher_enhancing_nodate,
	title        = {Enhancing {Data} {Visualization} {Literacy}: {A} {Comparative} {Study} of {Learning} {Materials} in {Schools}},
	shorttitle   = {Enhancing {Data} {Visualization} {Literacy}},
	author       = {Boucher, Magdalena and Kejstová, Magdaléna and Stoiber, Christina and Kandlhofer, Martin and Boucher, Alena and Kriglstein, Simone and Buchinger, Shelley and Aigner, Wolfgang},
	url          = {https://phaidra.ustp.at/detail/o:7302},
	urldate      = {2025-11-13},
	language     = {en}
}
@article{schottler_constraint-based_2025,
	title        = {Constraint-{Based} {Breakpoints} for {Responsive} {Visualization} {Design} and {Development}},
	author       = {Schöttler, Sarah and Dykes, Jason and Wood, Jo and Hinrichs, Uta and Bach, Benjamin},
	year         = 2025,
	month        = sep,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 31,
	number       = 9,
	pages        = {4593--4604},
	doi          = {10.1109/TVCG.2024.3410097},
	issn         = {1077-2626, 1941-0506, 2160-9306},
	url          = {https://ieeexplore.ieee.org/document/10549863/},
	urldate      = {2025-11-13},
	copyright    = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	abstract     = {This paper introduces constraint-based breakpoints, a technique for designing responsive visualizations for a wide variety of screen sizes and datasets. Breakpoints in responsive visualization define when different visualization designs are shown. Conventionally, breakpoints are static, pre-defined widths, and as such do not account for changes to the visualized dataset or visualization parameters. To guarantee readability and efficient use of space across datasets, these static breakpoints would require manual updates. Constraint-based breakpoints solve this by evaluating visualization-specific constraints on the size of visual elements, overlapping elements, and the aspect ratio of the visualization and available space. Once configured, a responsive visualization with constraint-based breakpoints can adapt to different screen sizes for any dataset. We describe a framework that guides designers in creating a stack of visualization designs for different display sizes and defining constraints for each of these designs. We demonstrate constraint-based breakpoints for different data types and their visualizations: geographic data (choropleth map, proportional circle map, Dorling cartogram, hexagonal grid map, bar chart, waffle chart), network data (nodelink diagram, adjacency matrix, arc diagram), and multivariate data (scatterplot, heatmap). Interactive demos and supplemental material are available at responsive-vis.github.io/breakpoints.},
	language     = {en}
}
@misc{schottler_constraint-based_2024,
	title        = {Constraint-{Based} {Breakpoints} for {Responsive} {Visualization} {Design} and {Development}},
	author       = {Schöttler, Sarah and Dykes, Jason and Wood, Jo and Hinrichs, Uta and Bach, Benjamin},
	year         = 2024,
	month        = sep,
	journal      = {arXiv.org},
	doi          = {10.1109/TVCG.2024.3410097},
	url          = {https://arxiv.org/abs/2409.01339v1},
	urldate      = {2025-11-13},
	abstract     = {This paper introduces constraint-based breakpoints, a technique for designing responsive visualizations for a wide variety of screen sizes and datasets. Breakpoints in responsive visualization define when different visualization designs are shown. Conventionally, breakpoints are static, pre-defined widths, and as such do not account for changes to the visualized dataset or visualization parameters. To guarantee readability and efficient use of space across datasets, these static breakpoints would require manual updates. Constraint-based breakpoints solve this by evaluating visualization-specific constraints on the size of visual elements, overlapping elements, and the aspect ratio of the visualization and available space. Once configured, a responsive visualization with constraint-based breakpoints can adapt to different screen sizes for any dataset. We describe a framework that guides designers in creating a stack of visualization designs for different display sizes and defining constraints for each of these designs. We demonstrate constraint-based breakpoints for different data types and their visualizations: geographic data (choropleth map, proportional circle map, Dorling cartogram, hexagonal grid map, bar chart, waffle chart), network data (node-link diagram, adjacency matrix, arc diagram), and multivariate data (scatterplot, heatmap). Interactive demos and supplemental material are available at https://responsive-vis.github.io/breakpoints/.},
	language     = {en}
}
@article{li_data_2025,
	title        = {Data {Speaks}, {But} {Who} {Gives} {It} a {Voice}? {Understanding} {Persuasive} Strategies in {Data}-{Driven} {News} {Articles}},
	author       = {Li, Zikai and Zheng, Chuyi and Li, Ziang and Shi, Yang},
	year         = 2025,
	keywords     = {Data Journalism}
}
@inproceedings{shneiderman_strategies_2006-1,
	title        = {Strategies for evaluating information visualization tools: multi-dimensional in-depth long-term case studies},
	author       = {Shneiderman, Ben and Plaisant, Catherine},
	year         = 2006,
	booktitle    = {Proceedings of the 2006 {AVI} workshop on {BEyond} time and errors: novel evaluation methods for information visualization},
	pages        = {1--7},
	url          = {https://www.cs.umd.edu/users/ben/papers/Shneiderman2006Strategies.pdf}
}
@article{rogers_insights_2020,
	title        = {Insights from experiments with rigor in an evobio design study},
	author       = {Rogers, Jen and Patton, Austin H and Harmon, Luke and Lex, Alexander and Meyer, Miriah},
	year         = 2020,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 27,
	number       = 2,
	pages        = {1106--1116},
	url          = {https://arxiv.org/pdf/2008.11564}
}
@inproceedings{mccurdy_galstamps_2019,
	title        = {{GalStamps}: {Analyzing} real and simulated galaxy observations},
	author       = {McCurdy, Nina and Meyer, Miriah},
	year         = 2019,
	booktitle    = {2019 {IEEE} visualization conference ({VIS})},
	publisher    = {IEEE},
	pages        = {276--280}
}
@article{rae_fox_quantifying_2025,
	title        = {Quantifying {Visualization} {Vibes}:{Measuring} {Socio}-{Indexicality} at {Scale}},
	author       = {Rae Fox, Amy and Morgenstern, Amy and M. Jones, Graham and Satyanaryan, Arvind},
	year         = 2025
}
@misc{ziman_it_2025,
	title        = {"{It} looks sexy but it's wrong." {Tensions} in creativity and accuracy using {genAI} for biomedical visualization},
	author       = {Ziman, Roxanne and Saharan, Shehryar and McGill, Gaël and Garrison, Laura},
	year         = 2025,
	url          = {https://arxiv.org/abs/2507.14494},
	note         = {\_eprint: 2507.14494},
	abstract     = {We contribute an in-depth analysis of the workflows and tensions arising from generative AI (genAI) use in biomedical visualization (BioMedVis). Although genAI affords facile production of aesthetic visuals for biological and medical content, the architecture of these tools fundamentally limits the accuracy and trustworthiness of the depicted information, from imaginary (or fanciful) molecules to alien anatomy. Through 17 interviews with a diverse group of practitioners and researchers, we qualitatively analyze the concerns and values driving genAI (dis)use for the visual representation of spatially-oriented biomedical data. We find that BioMedVis experts, both in roles as developers and designers, use genAI tools at different stages of their daily workflows and hold attitudes ranging from enthusiastic adopters to skeptical avoiders of genAI. In contrasting the current use and perspectives on genAI observed in our study with predictions towards genAI in the visualization pipeline from prior work, we refocus the discussion of genAI's effects on projects in visualization in the here and now with its respective opportunities and pitfalls for future visualization research. At a time when public trust in science is in jeopardy, we are reminded to first do no harm, not just in biomedical visualization but in science communication more broadly. Our observations reaffirm the necessity of human intervention for empathetic design and assessment of accurate scientific visuals.}
}
@article{bailey_anchoring_nodate,
	title        = {Anchoring and {Alignment}: {Data} {Factors} in {Part}-to-{Whole} {Visualization}},
	author       = {Bailey, Connor and Gleicher, Michael},
	abstract     = {We explore the effects of data and design considerations through the example case of part-to-whole data relationships. Standard part-towhole representations like pie charts and stacked bar charts make the relationships of parts to the whole explicit. Value estimation in these charts benefits from two perceptual mechanisms: anchoring, where the value is close to a reference value with an easily recognized shape, and alignment where the beginning or end of the shape is aligned with a marker. In an online study, we explore how data and design factors such as value, position, and encoding together impact these effects in making estimations in part-to-whole charts. The results show how salient values and alignment to positions on a scale affect task performance. This demonstrates the need for informed visualization design based around how data properties and design factors affect perceptual mechanisms.},
	language     = {en}
}
@inproceedings{ying_loh_rejecting_2025,
	title        = {Rejecting {Colonial} {Practices} in {Data} {Storytelling}},
	author       = {Ying Loh, Pei and Said, Nabilah and Gabriele, Griselda and Mansoor, Munriah and Zein, Zafirah and Teo, Amanda},
	year         = 2025,
	abstract     = {Given the difficulties and inherent problems of data, how do we approach data representations in a decolonial way? This annotated portfolio by Kontinentalist illustrates our evolving practice and attempt at forging a path grounded in a community manifesto that looks to challenge the need for accuracy and certainty, centring design in Indigenous vernacular and knowledge, and challenging reductivism.}
}
@article{warchol_seal_2025,
	title        = {{SEAL}: {Spatially}-resolved {Embedding} {Analysis} with {Linked} {Imaging} {Data}},
	author       = {Warchol, Simon and Guo, Grace and Knittel, Johannes and Freeman, Dan and Bhalla, Usha and Muhlich, Jeremy L and Sorger, Peter K. and Pfister, Hanspeter},
	year         = 2025,
	journal      = {bioRxiv},
	doi          = {10.1101/2025.07.19.665696},
	url          = {https://www.biorxiv.org/content/early/2025/07/28/2025.07.19.665696.1},
	note         = {Publisher: Cold Spring Harbor Laboratory \_eprint: https://www.biorxiv.org/content/early/2025/07/28/2025.07.19.665696.1.full.pdf},
	abstract     = {Dimensionality reduction techniques help analysts make sense of complex, high-dimensional spatial datasets, such as multiplexed tissue imaging, satellite imagery, and astronomical observations, by projecting data attributes into a two-dimensional space. However, these techniques typically abstract away crucial spatial, positional, and morphological contexts, complicating interpretation and limiting insights. To address these limitations, we present SEAL, an interactive visual analytics system designed to bridge the gap between abstract 2D embeddings and their rich spatial imaging context. SEAL introduces a novel hybrid-embedding visualization that preserves image and morphological information while integrating critical high-dimensional feature data. By adapting set visualization methods, SEAL allows analysts to identify, visualize, and compare selections—defined manually or algorithmically—in both the embedding and original spatial views, facilitating a deeper understanding of the spatial arrangement and morphological characteristics of entities of interest. To elucidate differences between selected sets of items, SEAL employs a scalable surrogate model to calculate feature importance scores, identifying the most influential features governing the position of objects within embeddings. These importance scores are visually summarized across selections, with mathematical set operations enabling detailed comparative analyses. We demonstrate SEAL’s effectiveness and versatility through three case studies: colorectal cancer tissue analysis with a pharmacologist, melanoma investigation with a cell biologist, and exploration of sky survey data with an astronomer. These studies underscore the importance of integrating image context into embedding spaces when interpreting complex imaging datasets. Implemented as a standalone tool while also integrating seamlessly with computational notebooks, SEAL provides an interactive platform for spatially informed exploration of high-dimensional datasets, significantly enhancing interpretability and insight generation.Competing Interest StatementThe authors have declared no competing interest.National Institutes of Health, https://ror.org/01cwqze88, U01CA284207, R01HD104969}
}
@article{lekschas_hipiler_2018,
	title        = {{HiPiler}: {Visual} {Exploration} of {Large} {Genome} {Interaction} {Matrices} with {Interactive} {Small} {Multiples}},
	shorttitle   = {{HiPiler}},
	author       = {Lekschas, Fritz and Bach, Benjamin and Kerpedjiev, Peter and Gehlenborg, Nils and Pfister, Hanspeter},
	year         = 2018,
	month        = jan,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 24,
	number       = 1,
	pages        = {522--531},
	doi          = {10.1109/TVCG.2017.2745978},
	issn         = {1941-0506},
	url          = {https://ieeexplore.ieee.org/abstract/document/8017587},
	urldate      = {2025-11-12},
	abstract     = {This paper presents an interactive visualization interface-HiPiler-for the exploration and visualization of regions-of-interest in large genome interaction matrices. Genome interaction matrices approximate the physical distance of pairs of regions on the genome to each other and can contain up to 3 million rows and columns with many sparse regions. Regions of interest (ROIs) can be defined, e.g., by sets of adjacent rows and columns, or by specific visual patterns in the matrix. However, traditional matrix aggregation or pan-and-zoom interfaces fail in supporting search, inspection, and comparison of ROIs in such large matrices. In HiPiler, ROIs are first-class objects, represented as thumbnail-like “snippets”. Snippets can be interactively explored and grouped or laid out automatically in scatterplots, or through dimension reduction methods. Snippets are linked to the entire navigable genome interaction matrix through brushing and linking. The design of HiPiler is based on a series of semi-structured interviews with 10 domain experts involved in the analysis and interpretation of genome interaction matrices. We describe six exploration tasks that are crucial for analysis of interaction matrices and demonstrate how HiPiler supports these tasks. We report on a user study with a series of data exploration sessions with domain experts to assess the usability of HiPiler as well as to demonstrate respective findings in the data.},
	keywords     = {Algorithm design and analysis, Bioinformatics, Biomedical Visualization, Data visualization, Genomics, Interactive Small Multiples, Interviews, Matrix Comparison, Visualization}
}
@article{mccurdy_framework_2018,
	title        = {A framework for externalizing implicit error using visualization},
	author       = {McCurdy, Nina and Gerdes, Julie and Meyer, Miriah},
	year         = 2018,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 25,
	number       = 1,
	pages        = {925--935}
}
@article{mccurdy_poemage_2015,
	title        = {Poemage: {Visualizing} the sonic topology of a poem},
	author       = {McCurdy, Nina and Lein, Julie and Coles, Katharine and Meyer, Miriah},
	year         = 2015,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 22,
	number       = 1,
	pages        = {439--448}
}
@article{bladin_globe_2018,
	title        = {Globe {Browsing}: {Contextualized} {Spatio}-{Temporal} {Planetary} {Surface} {Visualization}},
	author       = {Bladin, Karl and Axelsson, Emil and Broberg, Erik and Emmart, Carter and Ljung, Patric and Bock, Alexander and Ynnerman, Anders},
	year         = 2018,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 24,
	number       = 1,
	pages        = {802--811},
	doi          = {10.1109/TVCG.2017.2743958},
	abstract     = {Results of planetary mapping are often shared openly for use in scientific research and mission planning. In its raw format, however, the data is not accessible to non-experts due to the difficulty in grasping the context and the intricate acquisition process. We present work on tailoring and integration of multiple data processing and visualization methods to interactively contextualize geospatial surface data of celestial bodies for use in science communication. As our approach handles dynamic data sources, streamed from online repositories, we are significantly shortening the time between discovery and dissemination of data and results. We describe the image acquisition pipeline, the pre-processing steps to derive a 2.5D terrain, and a chunked level-of-detail, out-of-core rendering approach to enable interactive exploration of global maps and high-resolution digital terrain models. The results are demonstrated for three different celestial bodies. The first case addresses high-resolution map data on the surface of Mars. A second case is showing dynamic processes, such as concurrent weather conditions on Earth that require temporal datasets. As a final example we use data from the New Horizons spacecraft which acquired images during a single flyby of Pluto. We visualize the acquisition process as well as the resulting surface data. Our work has been implemented in the OpenSpace software [8], which enables interactive presentations in a range of environments such as immersive dome theaters, interactive touch tables, and virtual reality headsets.},
	keywords     = {Astronomical visualization, Data visualization, Earth, Mars, Pluto, Rendering (computer graphics), Surface treatment, globe rendering, public dissemination, science communication, space mission visualization}
}
@inproceedings{nagel_toward_2025,
	title        = {Toward a {Design} {Space} for {Embedded} {Urban} {Data} {Visualizations}},
	author       = {Nagel, Till and Huber, Christoph and Eder, Mona},
	year         = 2025,
	booktitle    = {{IEEE} {VIS} 2025 {Short} {Papers}},
	publisher    = {IEEE},
	address      = {Vienna, Austria},
	url          = {https://ieeevis.org/year/2025/program/paper_2bf2b86a-9987-4815-8c2a-8911b3588071.html}
}
@article{bach_time_2016,
	title        = {Time {Curves}: {Folding} {Time} to {Visualize} {Patterns} of {Temporal} {Evolution} in {Data}},
	shorttitle   = {Time {Curves}},
	author       = {Bach, Benjamin and Shi, Conglei and Heulot, Nicolas and Madhyastha, Tara and Grabowski, Tom and Dragicevic, Pierre},
	year         = 2016,
	month        = jan,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 22,
	number       = 1,
	pages        = {559--568},
	doi          = {10.1109/TVCG.2015.2467851},
	issn         = {1941-0506},
	url          = {https://ieeexplore.ieee.org/document/7192639},
	urldate      = {2025-10-30},
	abstract     = {We introduce time curves as a general approach for visualizing patterns of evolution in temporal data. Examples of such patterns include slow and regular progressions, large sudden changes, and reversals to previous states. These patterns can be of interest in a range of domains, such as collaborative document editing, dynamic network analysis, and video analysis. Time curves employ the metaphor of folding a timeline visualization into itself so as to bring similar time points close to each other. This metaphor can be applied to any dataset where a similarity metric between temporal snapshots can be defined, thus it is largely datatype-agnostic. We illustrate how time curves can visually reveal informative patterns in a range of different datasets.},
	keywords     = {Data visualization, Electronic publishing, Encyclopedias, History, Internet, Temporal data visualization, Visualization, information visualization, multidimensional scaling}
}
@misc{yeh_story_2025,
	title        = {Story {Ribbons}: {Reimagining} {Storyline} {Visualizations} with {Large} {Language} {Models}},
	shorttitle   = {Story {Ribbons}},
	author       = {Yeh, Catherine and Menon, Tara and Arya, Robin Singh and He, Helen and Weigel, Moira and Viégas, Fernanda and Wattenberg, Martin},
	year         = 2025,
	month        = aug,
	publisher    = {arXiv},
	doi          = {10.48550/arXiv.2508.06772},
	url          = {http://arxiv.org/abs/2508.06772},
	urldate      = {2025-11-10},
	note         = {arXiv:2508.06772 [cs]},
	abstract     = {Analyzing literature involves tracking interactions between characters, locations, and themes. Visualization has the potential to facilitate the mapping and analysis of these complex relationships, but capturing structured information from unstructured story data remains a challenge. As large language models (LLMs) continue to advance, we see an opportunity to use their text processing and analysis capabilities to augment and reimagine existing storyline visualization techniques. Toward this goal, we introduce an LLM-driven data parsing pipeline that automatically extracts relevant narrative information from novels and scripts. We then apply this pipeline to create STORY RIBBONS, an interactive visualization system that helps novice and expert literary analysts explore detailed character and theme trajectories at multiple narrative levels. Through pipeline evaluations and user studies with STORY RIBBONS on 36 literary works, we demonstrate the potential of LLMs to streamline narrative visualization creation and reveal new insights about familiar stories. We also describe current limitations of AI-based systems, and interaction motifs designed to address these issues.},
	language     = {en},
	keywords     = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning}
}
@misc{khalaila_they_2025,
	title        = {"{They} {Aren}'t {Built} {For} {Me}": {An} {Exploratory} {Study} of {Strategies} for {Measurement} of {Graphical} {Primitives} in {Tactile} {Graphics}},
	shorttitle   = {"{They} {Aren}'t {Built} {For} {Me}"},
	author       = {Khalaila, Areen and Harrison, Lane and Kim, Nam Wook and Cashman, Dylan},
	year         = 2025,
	month        = aug,
	publisher    = {arXiv},
	doi          = {10.48550/arXiv.2508.14289},
	url          = {http://arxiv.org/abs/2508.14289},
	urldate      = {2025-11-10},
	note         = {arXiv:2508.14289 [cs]},
	abstract     = {Advancements in accessibility technologies such as low-cost swell form printers or refreshable tactile displays promise to allow blind or low-vision (BLV) people to analyze data by transforming visual representations directly to tactile representations. However, it is possible that design guidelines derived from experiments on the visual perception system may not be suited for the tactile perception system. We investigate the potential mismatch between familiar visual encodings and tactile perception in an exploratory study into the strategies employed by BLV people to measure common graphical primitives converted to tactile representations. First, we replicate the Cleveland and McGill study on graphical perception using swell form printing with eleven BLV subjects. Then, we present results from a group interview in which we describe the strategies used by our subjects to read four common chart types. While our results suggest that familiar encodings based on visual perception studies can be useful in tactile graphics, our subjects also expressed a desire to use encodings designed explicitly for BLV people. Based on this study, we identify gaps between the perceptual expectations of common charts and the perceptual tools available in tactile perception. Then, we present a set of guidelines for the design of tactile graphics that accounts for these gaps. Supplemental material is available at https://osf.io/3nsfp/?view\_ only=7b7b8dcbae1d4c9a8bb4325053d13d9f.},
	language     = {en},
	keywords     = {Computer Science - Human-Computer Interaction}
}
@article{marai_activity-centered_2018,
	title        = {Activity-{Centered} {Domain} {Characterization} for {Problem}-{Driven} {Scientific} {Visualization}},
	author       = {Marai, G. Elisabeta},
	year         = 2018,
	month        = jan,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 24,
	number       = 1,
	pages        = {913--922},
	doi          = {10.1109/TVCG.2017.2744459},
	issn         = {1941-0506},
	abstract     = {Although visualization design models exist in the literature in the form of higher-level methodological frameworks, these models do not present a clear methodological prescription for the domain characterization step. This work presents a framework and end-to-end model for requirements engineering in problem-driven visualization application design. The framework and model are based on the activity-centered design paradigm, which is an enhancement of human-centered design. The proposed activity-centered approach focuses on user tasks and activities, and allows an explicit link between the requirements engineering process with the abstraction stage-and its evaluation-of existing, higher-level visualization design models. In a departure from existing visualization design models, the resulting model: assigns value to a visualization based on user activities; ranks user tasks before the user data; partitions requirements in activity-related capabilities and nonfunctional characteristics and constraints; and explicitly incorporates the user workflows into the requirements process. A further merit of this model is its explicit integration of functional specifications, a concept this work adapts from the software engineering literature, into the visualization design nested model. A quantitative evaluation using two sets of interdisciplinary projects supports the merits of the activity-centered model. The result is a practical roadmap to the domain characterization step of visualization design for problem-driven data visualization. Following this domain characterization model can help remove a number of pitfalls that have been identified multiple times in the visualization design literature.},
	language     = {eng},
	pmid         = 28866550,
	pmcid        = {PMC5796424},
	keywords     = {Algorithms, Computer Graphics, Humans, Software, User-Computer Interface, Visual Perception}
}
@article{bujack_good_2018,
	title        = {The {Good}, the {Bad}, and the {Ugly}: {A} {Theoretical} {Framework} for the {Assessment} of {Continuous} {Colormaps}},
	author       = {Bujack, Roxana and Turton, Terece L. and Samsel, Francesca and Ware, Colin and Rogers, David H. and Ahrens, James},
	year         = 2018,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 24,
	number       = 1,
	pages        = {923--933},
	doi          = {10.1109/TVCG.2017.2743978},
	keywords     = {Brightness, Color, Image color analysis, Linearity, Sensitivity, Taxonomy, colormap, discriminative power, linearity, monotonicity, order, smoothness, speed, survey, taxonomy, uniformity}
}
@article{he_reframing_2025,
	title        = {Reframing {Pattern}: {A} {Comprehensive} {Approach} to a {Composite} {Visual} {Variable}},
	author       = {He, Tingying and Dykes, Jason and Isenberg, Petra and Isenberg, Tobias},
	year         = 2025,
	journal      = {arXiv preprint arXiv:2508.02639}
}
@inproceedings{dykes_cartographic_1995,
	title        = {Cartographic visualization for spatial analysis},
	author       = {Dykes, Jason A},
	year         = 1995,
	booktitle    = {Proceedings {ICA} / {ACI} - {International} {Cartographic} {Conference}},
	address      = {Barcelona, Catalunya},
	pages        = {1365--1370}
}
@article{willett_perception_2021,
	title        = {Perception! immersion! empowerment! superpowers as inspiration for visualization},
	author       = {Willett, Wesley and Aseniero, Bon Adriel and Carpendale, Sheelagh and Dragicevic, Pierre and Jansen, Yvonne and Oehlberg, Lora and Isenberg, Petra},
	year         = 2021,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 28,
	number       = 1,
	pages        = {22--32},
	doi          = {https://doi.org/10.1109/TVCG.2021.3114844},
	url          = {https://arxiv.org/pdf/2108.03524}
}
@incollection{munzner_process_2008,
	title        = {Process and pitfalls in writing information visualization research papers},
	author       = {Munzner, Tamara},
	year         = 2008,
	booktitle    = {Information visualization: human-centered issues and perspectives},
	publisher    = {Springer},
	pages        = {134--153}
}
@article{munzner_nested_2009,
	title        = {A nested model for visualization design and validation},
	author       = {Munzner, Tamara},
	year         = 2009,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 15,
	number       = 6,
	pages        = {921--928}
}
@article{wood_ballotmaps_2011,
	title        = {{BallotMaps}: {Detecting} name bias in alphabetically ordered ballot papers},
	author       = {Wood, Jo and Badawood, Donia and Dykes, Jason and Slingsby, Aidan},
	year         = 2011,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 17,
	number       = 12,
	pages        = {2384--2391},
	doi          = {https://doi.org/10.1109/TVCG.2011.174},
	url          = {https://openaccess.city.ac.uk/id/eprint/436/1/wood_ballotmaps_2011.pdf}
}
@article{jiang_design_2025,
	title        = {Design {Guidelines} for {Animated} {Data} {Visualization} {Based} on {Perceptual} {Capacity} {Limits}},
	author       = {Jiang, Ouxun and Matuk, Camillia and Gopalakrishnan, Madhumitha and Xu, Wen and Dykes, Jason and Bezerianos, Anastasia and Chevalier, Fanny and Isenberg, Petra and Franconeri, Steven},
	year         = 2025
}

@inproceedings{aerts_me-ifestos_2022,
	title        = {Me-ifestos for visualization empowerment in teaching (and learning?)},
	author       = {Aerts, Jan and Aigner, Wolfgang and Bach, Benjamin and Bishop, Fearn and Boucher, Magdalena and Cheng, Peter C-H and Diehl, Alexandra and Dykes, Jason and Hayes, Sarah and Hinrichs, Uta and {others}},
	year         = 2022,
	publisher    = {IEEE},
	address      = {Oklahoma City, OK},
	url          = {https://altvis.github.io/2022.html#meifestos},
	note         = {https://altvis.github.io/papers/2022/meifestos.pdf}
}
@article{cleveland_graphical_1984,
	title        = {Graphical {Perception}: {Theory}, {Experimentation}, and {Application} to the {Development} of {Graphical} {Methods}},
	author       = {Cleveland, William S. and McGill, Robert},
	year         = 1984,
	journal      = {Journal of the American Statistical Association},
	volume       = 79,
	number       = 387,
	pages        = {531--554},
	doi          = {https://doi.org/10.2307/2288400},
	issn         = {01621459, 1537274X},
	url          = {http://www.jstor.org/stable/2288400},
	urldate      = {2025-11-28},
	copyright    = {Shared for scholarly purposes in group instruction setting under JSTOR Terms and Conditions of Use https://about.jstor.org/terms/\#content-use},
	abstract     = {[The subject of graphical methods for data analysis and for data presentation needs a scientific foundation. In this article we take a few steps in the direction of establishing such a foundation. Our approach is based on graphical perception-the visual decoding of information encoded on graphs-and it includes both theory and experimentation to test the theory. The theory deals with a small but important piece of the whole process of graphical perception. The first part is an identification of a set of elementary perceptual tasks that are carried out when people extract quantitative information from graphs. The second part is an ordering of the tasks on the basis of how accurately people perform them. Elements of the theory are tested by experimentation in which subjects record their judgments of the quantitative information on graphs. The experiments validate these elements but also suggest that the set of elementary tasks should be expanded. The theory provides a guideline for graph construction: Graphs should employ elementary tasks as high in the ordering as possible. This principle is applied to a variety of graphs, including bar charts, divided bar charts, pie charts, and statistical maps with shading. The conclusion is that radical surgery on these popular graphs is needed, and as replacements we offer alternative graphical forms-dot charts, dot charts with grouping, and framed-rectangle charts.]}
}
@article{wood_sketchy_2012,
	title        = {Sketchy rendering for information visualization},
	author       = {Wood, Jo and Isenberg, Petra and Isenberg, Tobias and Dykes, Jason and Boukhelifa, Nadia and Slingsby, Aidan},
	year         = 2012,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 18,
	number       = 12,
	pages        = {2749--2758},
	doi          = {https://doi.org/10.1109/TVCG.2012.262},
	url          = {https://ieeexplore.ieee.org/abstract/document/6327281},
	copyright    = {
		Copyright: City Research Online aims to make research outputs of City,University of London available to a wider audience. Copyright and Moral Rights remain with the author(s) and/or copyright holders. URLs from City ResearchOnline may be freely distributed and linked to.

		Reuse: Copies of full items can be used for personal research or study, educational, or not-for-profit purposes without prior permission or charge.Provided that the authors, title and full bibliographic details are credited, a hyperlink and/or URL is given for the original metadata page and the content is not changed in any way.
	}
}
@article{pena-araya_comparison_2019,
	title        = {A comparison of visualizations for identifying correlation over space and time},
	author       = {Peña-Araya, Vanessa and Pietriga, Emmanuel and Bezerianos, Anastasia},
	year         = 2019,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 26,
	number       = 1,
	pages        = {375--385},
	doi          = {https://doi.org/10.1145/3313831.3376350},
	url          = {https://dl.acm.org/doi/abs/10.1145/3313831.3376350},
	copyright    = {© 2019 IEEE. This is the author’s version of the article that has been published in IEEE Transactions on Visualization and Computer Graphics. The final version of this record is available at: 10.1109/TVCG.2019.2934807}
}
@inproceedings{heer_crowdsourcing_2010,
	title        = {Crowdsourcing graphical perception: using mechanical turk to assess visualization design},
	author       = {Heer, Jeffrey and Bostock, Michael},
	year         = 2010,
	booktitle    = {Proceedings of the {SIGCHI} conference on human factors in computing systems},
	pages        = {203--212},
	copyright    = {Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.}
}
@article{chevalier_not-so-staggering_2014,
	title        = {The not-so-staggering effect of staggered animated transitions on visual tracking},
	author       = {Chevalier, Fanny and Dragicevic, Pierre and Franconeri, Steven},
	year         = 2014,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 20,
	number       = 12,
	pages        = {2241--2250},
	doi          = {https://dx.doi.org/10.1109/TVCG.2014.2346424},
	url          = {https://inria.hal.science/hal-01054408/document/},
	copyright    = {No rights listed - downloaded from HAL. Looks like an author copy, therefore likely to be legitimately shared for educational purposes.}
}
@article{park_gatherplot_2023,
	title        = {Gatherplot: {A} {Non}-{Overlapping} {Scatterplot}},
	author       = {Park, Deokgun and Kim, Sung-Hee and Elmqvist, Niklas},
	year         = 2023,
	journal      = {Journal of Visualization and Interaction},
	doi          = {https://doi.org/10.54337/jovi.v1i1.8540},
	url          = {https://journals.aau.dk/index.php/jovi/article/view/8540},
	copyright    = {This work is licensed under a Creative Commons Attribution 4.0 International (CC-BY 4.0) license. All copyrights remain with the authors.}
}
@inproceedings{fuchs_evaluation_2013,
	title        = {Evaluation of alternative glyph designs for time series data in a small multiple setting},
	author       = {Fuchs, Johannes and Fischer, Fabian and Mansmann, Florian and Bertini, Enrico and Isenberg, Petra},
	year         = 2013,
	booktitle    = {Proceedings of the {SIGCHI} conference on human factors in computing systems},
	pages        = {3237--3246},
	url          = {https://inria.hal.science/hal-00781504/document},
	copyright    = {Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.}
}
@article{ashcroft_suggested_2025,
	title        = {Suggested {Prompts} for {Reflexivity}: {Navigating} {Intersectionality} in {HCI} and {CSCW} {Research}},
	author       = {Ashcroft, Alice and Severes, Beatriz and Martinez-Perez, Melissa},
	year         = 2025,
	journal      = {Interacting with Computers},
	pages        = {iwaf007},
	url          = {https://academic.oup.com/iwc/article/37/5/397/8063672},
	copyright    = {© The Author(s) 2025. Published by Oxford University Press on behalf of The British Computer Society. This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited.}
}
@article{malterud_qualitative_2001,
	title        = {Qualitative research: standards, challenges, and guidelines},
	author       = {Malterud, Kirsti},
	year         = 2001,
	journal      = {The Lancet},
	volume       = 358,
	number       = 9280,
	pages        = {483--488},
	doi          = {https://doi.org/10.1016/S0140-6736(01)05627-6},
	url          = {https://doi.org/10.1016/S0140-6736(01)05627-6},
	copyright    = {Only available through ScienceDirect (paywall) - "For personal use. Only reproduce with permission from The Lancet Publishing Group."}
}
@inproceedings{singh_exploring_2025,
	title        = {Exploring positionality in {HCI}: {Perspectives}, trends, and challenges},
	author       = {Singh, Aneesha and Dechant, Martin Johannes and Patel, Dilisha and Soubutts, Ewan and Barbareschi, Giulia and Ayobi, Amid and Newhouse, Nikki},
	year         = 2025,
	booktitle    = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	pages        = {1--18},
	copyright    = {CC-BY This work is licensed under a Creative Commons Attribution 4.0 International License. CHI ’25, Yokohama, Japan © 2025 Copyright held by the owner/author(s).}
}
@article{meyer_criteria_2019,
	title        = {Criteria for rigor in visualization design study},
	author       = {Meyer, Miriah and Dykes, Jason},
	year         = 2019,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 26,
	number       = 1,
	pages        = {87--97}
}
@article{sein_action_2011,
	title        = {Action design research},
	author       = {Sein, Maung K and Henfridsson, Ola and Purao, Sandeep and Rossi, Matti and Lindgren, Rikard},
	year         = 2011,
	journal      = {MIS quarterly},
	pages        = {37--56},
	url          = {https://www.jstor.org/stable/pdf/23043488}
}
@inproceedings{mccurdy_action_2016,
	title        = {Action design research and visualization design},
	shorttitle   = {https://openaccess.city.ac.uk/id/eprint/15270/},
	author       = {McCurdy, Nina and Dykes, Jason and Meyer, Miriah},
	year         = 2016,
	booktitle    = {Proceedings of the {Sixth} {Workshop} on {Beyond} {Time} and {Errors} on {Novel} {Evaluation} {Methods} for {Visualization}},
	publisher    = {ACM},
	pages        = {10--18},
	url          = {https://dl.acm.org/doi/pdf/10.1145/2993901.2993916}
}
@inproceedings{wood_beyond_2022,
	title        = {Beyond the {Walled} {Garden}.},
	author       = {Wood, Jo},
	year         = 2022,
	booktitle    = {alt.{VIS} - 2022},
	publisher    = {IEEE},
	address      = {Oklahoma City, OK},
	url          = {https://altvis.github.io/papers/2022/walled-garden.pdf}
}
@article{kerzner_framework_2018,
	title        = {A framework for creative visualization-opportunities workshops},
	author       = {Kerzner, Ethan and Goodwin, Sarah and Dykes, Jason and Jones, Sara and Meyer, Miriah},
	year         = 2018,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 25,
	number       = 1,
	pages        = {748--758},
	url          = {https://arxiv.org/pdf/1808.02502}
}
@article{goodwin_creative_2013,
	title        = {Creative user-centered visualization design for energy analysts and modelers},
	author       = {Goodwin, Sarah and Dykes, Jason and Jones, Sara and Dillingham, Iain and Dove, Graham and Duffy, Alison and Kachkaev, Alexander and Slingsby, Aidan and Wood, Jo},
	year         = 2013,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 19,
	number       = 12,
	pages        = {2516--2525},
	url          = {https://openaccess.city.ac.uk/id/eprint/2618/5/Goodwin-preprint.pdf}
}
@article{hall_design_2019,
	title        = {Design by {Immersion}: {A} transdisciplinary approach to problem-driven visualizations},
	author       = {Hall, Kyle Wm and Bradley, Adam J and Hinrichs, Uta and Huron, Samuel and Wood, Jo and Collins, Christopher and Carpendale, Sheelagh},
	year         = 2019,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 26,
	number       = 1,
	pages        = {109--118},
	url          = {https://arxiv.org/pdf/1908.00559}
}
@inproceedings{rijken_illegible_2021,
	title        = {Illegible semantics: {Exploring} the design space of metal logos},
	shorttitle   = {https://noeska.github.io/illegiblesemantics/},
	author       = {Rijken, Gerrit J and Cutura, Rene and Heyen, Frank and Sedlmair, Michael and Correll, Michael and Dykes, Jason and Smit, Noeska},
	year         = 2021,
	booktitle    = {{arXiv} preprint {arXiv}:2109.01688},
	publisher    = {IEEE},
	address      = {New Orleans, LA},
	url          = {https://arxiv.org/pdf/2109.01688}
}
@inproceedings{varona_theory_2025,
	title        = {Theory is {Shapes}},
	author       = {Varona, Matthew and Hedayati, Maryam and Kay, Matthew and Nobre, Carolina},
	year         = 2025,
	booktitle    = {{arXiv} preprint {arXiv}:2510.01382},
	address      = {Vienna, Austria},
	url          = {https://altvis.github.io/#theory-is-shapes}
}
@inproceedings{shneiderman_strategies_2006,
	title        = {Strategies for evaluating information visualization tools: multi-dimensional in-depth long-term case studies},
	shorttitle   = {Strategies for evaluating information visualization tools},
	author       = {Shneiderman, Ben and Plaisant, Catherine},
	year         = 2006,
	month        = may,
	booktitle    = {Proceedings of the 2006 {AVI} workshop on {BEyond} time and errors: novel evaluation methods for information visualization},
	publisher    = {ACM},
	address      = {Venice Italy},
	pages        = {1--7},
	doi          = {10.1145/1168149.1168158},
	isbn         = {978-1-59593-562-5},
	url          = {https://dl.acm.org/doi/10.1145/1168149.1168158},
	urldate      = {2025-11-20},
	abstract     = {After an historical review of evaluation methods, we describe an emerging research method called Multi-dimensional In-depth Long-term Case studies (MILCs) which seems well adapted to study the creative activities that users of information visualization systems engage in. We propose that the efficacy of tools can be assessed by documenting 1) usage (observations, interviews, surveys, logging etc.) and 2) expert users’ success in achieving their professional goals. We summarize lessons from related ethnography methods used in HCI and provide guidelines for conducting MILCs for information visualization. We suggest ways to refine the methods for MILCs in modest sized projects and then envision ambitious projects with 3-10 researchers working over 1-3 years to understand individual and organizational use of information visualization by domain experts working at the frontiers of knowledge in their fields.},
	language     = {en}
}
@article{sedlmair_design_2012,
	title        = {Design {Study} {Methodology}: {Reflections} from the {Trenches} and the {Stacks}},
	shorttitle   = {Design {Study} {Methodology}},
	author       = {Sedlmair, Michael and Meyer, Miriah and Munzner, Tamara},
	year         = 2012,
	month        = dec,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 18,
	number       = 12,
	pages        = {2431--2440},
	doi          = {10.1109/TVCG.2012.213},
	issn         = {1077-2626},
	url          = {http://ieeexplore.ieee.org/document/6327248/},
	urldate      = {2025-11-19},
	copyright    = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	abstract     = {Design studies are an increasingly popular form of problem-driven visualization research, yet there is little guidance available about how to do them effectively. In this paper we reﬂect on our combined experience of conducting twenty-one design studies, as well as reading and reviewing many more, and on an extensive literature review of other ﬁeld work methods and methodologies. Based on this foundation we provide deﬁnitions, propose a methodological framework, and provide practical guidance for conducting design studies. We deﬁne a design study as a project in which visualization researchers analyze a speciﬁc real-world problem faced by domain experts, design a visualization system that supports solving this problem, validate the design, and reﬂect about lessons learned in order to reﬁne visualization design guidelines. We characterize two axes—a task clarity axis from fuzzy to crisp and an information location axis from the domain expert’s head to the computer—and use these axes to reason about design study contributions, their suitability, and uniqueness from other approaches. The proposed methodological framework consists of 9 stages: learn, winnow, cast, discover, design, implement, deploy, reﬂect, and write. For each stage we provide practical guidance and outline potential pitfalls. We also conducted an extensive literature survey of related methodological approaches that involve a signiﬁcant amount of qualitative ﬁeld work, and compare design study methodology to that of ethnography, grounded theory, and action research.},
	language     = {en}
}
@inproceedings{mccurdy_rhymedesign_2015,
	title        = {{RhymeDesign}: {A} {Tool} for {Analyzing} {Sonic} {Devices} in {Poetry}},
	shorttitle   = {{RhymeDesign}},
	author       = {McCurdy, Nina and Srikumar, Vivek and Meyer, Miriah},
	year         = 2015,
	booktitle    = {Proceedings of the {Fourth} {Workshop} on {Computational} {Linguistics} for {Literature}},
	publisher    = {Association for Computational Linguistics},
	address      = {Denver, Colorado, USA},
	pages        = {12--22},
	doi          = {10.3115/v1/W15-0702},
	url          = {http://aclweb.org/anthology/W15-0702},
	urldate      = {2025-11-20},
	abstract     = {The analysis of sound and sonic devices in poetry is the focus of much poetic scholarship, and poetry scholars are becoming increasingly interested in the role that computation might play in their research. Since the nature of such sonic analysis is unique, the associated tasks are not supported by standard text analysis techniques. We introduce a formalism for analyzing sonic devices in poetry. In addition, we present RhymeDesign, an open-source implementation of our formalism, through which poets and poetry scholars can explore their individual notion of rhyme.},
	language     = {en}
}
@inproceedings{jones_use_2008,
	title        = {Use and {Influence} of {Creative} {Ideas} and {Requirements} for a {Work}-{Integrated} {Learning} {System}},
	author       = {Jones, Sara and Lynch, Perry and Maiden, Neil and Lindstaedt, Stefanie},
	year         = 2008,
	month        = sep,
	booktitle    = {2008 16th {IEEE} {International} {Requirements} {Engineering} {Conference}},
	publisher    = {IEEE},
	address      = {Barcelona, Spain},
	pages        = {289--294},
	doi          = {10.1109/RE.2008.54},
	isbn         = {978-0-7695-3309-4},
	url          = {http://ieeexplore.ieee.org/document/4685684/},
	urldate      = {2025-11-19}
}
@article{pagani_unlocking_2025,
	title        = {Unlocking {Marketing} {Creativity} {Using} {Artificial} {Intelligence}},
	author       = {Pagani, Margherita and Wind, Yoram},
	year         = 2025,
	journal      = {Journal of Interactive Marketing},
	volume       = 60,
	number       = 1,
	pages        = {1--24},
	doi          = {10.1177/10949968241265855},
	url          = {https://doi.org/10.1177/10949968241265855},
	note         = {\_eprint: https://doi.org/10.1177/10949968241265855},
	abstract     = {This article examines the role of artificial intelligence (AI) in enhancing marketing creativity by analyzing the synergy between computational and human creative processes. Through two studies, the authors investigate nongenerative and generative AI applications within marketing contexts using a conceptually driven and empirically derived approach. In Study 1, the authors observe how creative individuals, particularly artists, utilize AI and its effects on their creative experiences, revealing AI's role as (1) a new instrumental resource, (2) a tool for exploring possibilities, and (3) a means to deconstruct the creative process. Study 2 assesses 1,036 AI systems (2015–2021) and 241,292 AI models (2022–2024), categorizing them into four clusters and three levels of observed creativity. From these insights, the authors introduce a framework for AI-enabled creativity: (1) inspiring agile methods, (2) augmenting human creativity, and (3) inspiring unconventional thinking. Validated by three workshops, this framework equips marketing leaders with a deeper comprehension of AI's creative potential. The authors advocate for AI integration within agile, augmented, and unconventional marketing approaches, advancing our understanding of AI's contribution to marketing creativity. Additionally, they propose a research roadmap for empirical validation in real-world applications.}
}
@misc{dellacqua_cybernetic_2025,
	title        = {The {Cybernetic} {Teammate}: {A} {Field} {Experiment} on {Generative} {AI} {Reshaping} {Teamwork} and {Expertise}},
	shorttitle   = {The {Cybernetic} {Teammate}},
	author       = {Dell'Acqua, Fabrizio and Ayoubi, Charles and Lifshitz-Assaf, Hila and Sadun, Raffaella and Mollick, Ethan R. and Mollick, Lilach and Han, Yi and Goldman, Jeff and Nair, Hari and Taub, Stew and Lakhani, Karim R.},
	year         = 2025,
	publisher    = {SSRN},
	doi          = {10.2139/ssrn.5188231},
	url          = {https://www.ssrn.com/abstract=5188231},
	urldate      = {2025-11-19}
}
@inproceedings{de_rooij_emotion_2015,
	title        = {Emotion and {Creativity}: {Hacking} into {Cognitive} {Appraisal} {Processes} to {Augment} {Creative} {Ideation}},
	shorttitle   = {Emotion and {Creativity}},
	author       = {De Rooij, Alwin and Corr, Philip J. and Jones, Sara},
	year         = 2015,
	month        = jun,
	booktitle    = {Proceedings of the 2015 {ACM} {SIGCHI} {Conference} on {Creativity} and {Cognition}},
	publisher    = {ACM},
	address      = {Glasgow United Kingdom},
	pages        = {265--274},
	doi          = {10.1145/2757226.2757227},
	isbn         = {978-1-4503-3598-0},
	url          = {https://dl.acm.org/doi/10.1145/2757226.2757227},
	urldate      = {2025-11-19},
	language     = {en}
}
@article{schottler_constraint-based_2025,
	title        = {Constraint-{Based} {Breakpoints} for {Responsive} {Visualization} {Design} and {Development}},
	author       = {Schöttler, Sarah and Dykes, Jason and Wood, Jo and Hinrichs, Uta and Bach, Benjamin},
	year         = 2025,
	month        = sep,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 31,
	number       = 9,
	pages        = {4593--4604},
	doi          = {10.1109/TVCG.2024.3410097},
	issn         = {1077-2626, 1941-0506, 2160-9306},
	url          = {https://ieeexplore.ieee.org/document/10549863/},
	urldate      = {2025-11-13},
	copyright    = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	abstract     = {This paper introduces constraint-based breakpoints, a technique for designing responsive visualizations for a wide variety of screen sizes and datasets. Breakpoints in responsive visualization define when different visualization designs are shown. Conventionally, breakpoints are static, pre-defined widths, and as such do not account for changes to the visualized dataset or visualization parameters. To guarantee readability and efficient use of space across datasets, these static breakpoints would require manual updates. Constraint-based breakpoints solve this by evaluating visualization-specific constraints on the size of visual elements, overlapping elements, and the aspect ratio of the visualization and available space. Once configured, a responsive visualization with constraint-based breakpoints can adapt to different screen sizes for any dataset. We describe a framework that guides designers in creating a stack of visualization designs for different display sizes and defining constraints for each of these designs. We demonstrate constraint-based breakpoints for different data types and their visualizations: geographic data (choropleth map, proportional circle map, Dorling cartogram, hexagonal grid map, bar chart, waffle chart), network data (nodelink diagram, adjacency matrix, arc diagram), and multivariate data (scatterplot, heatmap). Interactive demos and supplemental material are available at responsive-vis.github.io/breakpoints.},
	language     = {en}
}
@misc{schottler_constraint-based_2024,
	title        = {Constraint-{Based} {Breakpoints} for {Responsive} {Visualization} {Design} and {Development}},
	author       = {Schöttler, Sarah and Dykes, Jason and Wood, Jo and Hinrichs, Uta and Bach, Benjamin},
	year         = 2024,
	month        = sep,
	journal      = {arXiv.org},
	doi          = {10.1109/TVCG.2024.3410097},
	url          = {https://arxiv.org/abs/2409.01339v1},
	urldate      = {2025-11-13},
	abstract     = {This paper introduces constraint-based breakpoints, a technique for designing responsive visualizations for a wide variety of screen sizes and datasets. Breakpoints in responsive visualization define when different visualization designs are shown. Conventionally, breakpoints are static, pre-defined widths, and as such do not account for changes to the visualized dataset or visualization parameters. To guarantee readability and efficient use of space across datasets, these static breakpoints would require manual updates. Constraint-based breakpoints solve this by evaluating visualization-specific constraints on the size of visual elements, overlapping elements, and the aspect ratio of the visualization and available space. Once configured, a responsive visualization with constraint-based breakpoints can adapt to different screen sizes for any dataset. We describe a framework that guides designers in creating a stack of visualization designs for different display sizes and defining constraints for each of these designs. We demonstrate constraint-based breakpoints for different data types and their visualizations: geographic data (choropleth map, proportional circle map, Dorling cartogram, hexagonal grid map, bar chart, waffle chart), network data (node-link diagram, adjacency matrix, arc diagram), and multivariate data (scatterplot, heatmap). Interactive demos and supplemental material are available at https://responsive-vis.github.io/breakpoints/.},
	language     = {en}
}
@article{li_data_2025,
	title        = {Data {Speaks}, {But} {Who} {Gives} {It} a {Voice}? {Understanding} {Persuasive} Strategies in {Data}-{Driven} {News} {Articles}},
	author       = {Li, Zikai and Zheng, Chuyi and Li, Ziang and Shi, Yang},
	year         = 2025,
	keywords     = {Data Journalism}
}
@inproceedings{shneiderman_strategies_2006-1,
	title        = {Strategies for evaluating information visualization tools: multi-dimensional in-depth long-term case studies},
	author       = {Shneiderman, Ben and Plaisant, Catherine},
	year         = 2006,
	booktitle    = {Proceedings of the 2006 {AVI} workshop on {BEyond} time and errors: novel evaluation methods for information visualization},
	pages        = {1--7},
	url          = {https://www.cs.umd.edu/users/ben/papers/Shneiderman2006Strategies.pdf}
}
@article{rogers_insights_2020,
	title        = {Insights from experiments with rigor in an evobio design study},
	author       = {Rogers, Jen and Patton, Austin H and Harmon, Luke and Lex, Alexander and Meyer, Miriah},
	year         = 2020,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 27,
	number       = 2,
	pages        = {1106--1116},
	url          = {https://arxiv.org/pdf/2008.11564}
}
@inproceedings{mccurdy_galstamps_2019,
	title        = {{GalStamps}: {Analyzing} real and simulated galaxy observations},
	author       = {McCurdy, Nina and Meyer, Miriah},
	year         = 2019,
	booktitle    = {2019 {IEEE} visualization conference ({VIS})},
	publisher    = {IEEE},
	pages        = {276--280}
}
@article{rae_fox_quantifying_2025,
	title        = {Quantifying {Visualization} {Vibes}:{Measuring} {Socio}-{Indexicality} at {Scale}},
	author       = {Rae Fox, Amy and Morgenstern, Amy and M. Jones, Graham and Satyanaryan, Arvind},
	year         = 2025
}
@misc{ziman_it_2025,
	title        = {"{It} looks sexy but it's wrong." {Tensions} in creativity and accuracy using {genAI} for biomedical visualization},
	author       = {Ziman, Roxanne and Saharan, Shehryar and McGill, Gaël and Garrison, Laura},
	year         = 2025,
	url          = {https://arxiv.org/abs/2507.14494},
	note         = {\_eprint: 2507.14494},
	abstract     = {We contribute an in-depth analysis of the workflows and tensions arising from generative AI (genAI) use in biomedical visualization (BioMedVis). Although genAI affords facile production of aesthetic visuals for biological and medical content, the architecture of these tools fundamentally limits the accuracy and trustworthiness of the depicted information, from imaginary (or fanciful) molecules to alien anatomy. Through 17 interviews with a diverse group of practitioners and researchers, we qualitatively analyze the concerns and values driving genAI (dis)use for the visual representation of spatially-oriented biomedical data. We find that BioMedVis experts, both in roles as developers and designers, use genAI tools at different stages of their daily workflows and hold attitudes ranging from enthusiastic adopters to skeptical avoiders of genAI. In contrasting the current use and perspectives on genAI observed in our study with predictions towards genAI in the visualization pipeline from prior work, we refocus the discussion of genAI's effects on projects in visualization in the here and now with its respective opportunities and pitfalls for future visualization research. At a time when public trust in science is in jeopardy, we are reminded to first do no harm, not just in biomedical visualization but in science communication more broadly. Our observations reaffirm the necessity of human intervention for empathetic design and assessment of accurate scientific visuals.}
}
@inproceedings{ying_loh_rejecting_2025,
	title        = {Rejecting {Colonial} {Practices} in {Data} {Storytelling}},
	author       = {Ying Loh, Pei and Said, Nabilah and Gabriele, Griselda and Mansoor, Munriah and Zein, Zafirah and Teo, Amanda},
	year         = 2025,
	abstract     = {Given the difficulties and inherent problems of data, how do we approach data representations in a decolonial way? This annotated portfolio by Kontinentalist illustrates our evolving practice and attempt at forging a path grounded in a community manifesto that looks to challenge the need for accuracy and certainty, centring design in Indigenous vernacular and knowledge, and challenging reductivism.}
}
@article{warchol_seal_2025,
	title        = {{SEAL}: {Spatially}-resolved {Embedding} {Analysis} with {Linked} {Imaging} {Data}},
	author       = {Warchol, Simon and Guo, Grace and Knittel, Johannes and Freeman, Dan and Bhalla, Usha and Muhlich, Jeremy L and Sorger, Peter K. and Pfister, Hanspeter},
	year         = 2025,
	journal      = {bioRxiv},
	doi          = {10.1101/2025.07.19.665696},
	url          = {https://www.biorxiv.org/content/early/2025/07/28/2025.07.19.665696.1},
	note         = {Publisher: Cold Spring Harbor Laboratory \_eprint: https://www.biorxiv.org/content/early/2025/07/28/2025.07.19.665696.1.full.pdf},
	abstract     = {Dimensionality reduction techniques help analysts make sense of complex, high-dimensional spatial datasets, such as multiplexed tissue imaging, satellite imagery, and astronomical observations, by projecting data attributes into a two-dimensional space. However, these techniques typically abstract away crucial spatial, positional, and morphological contexts, complicating interpretation and limiting insights. To address these limitations, we present SEAL, an interactive visual analytics system designed to bridge the gap between abstract 2D embeddings and their rich spatial imaging context. SEAL introduces a novel hybrid-embedding visualization that preserves image and morphological information while integrating critical high-dimensional feature data. By adapting set visualization methods, SEAL allows analysts to identify, visualize, and compare selections—defined manually or algorithmically—in both the embedding and original spatial views, facilitating a deeper understanding of the spatial arrangement and morphological characteristics of entities of interest. To elucidate differences between selected sets of items, SEAL employs a scalable surrogate model to calculate feature importance scores, identifying the most influential features governing the position of objects within embeddings. These importance scores are visually summarized across selections, with mathematical set operations enabling detailed comparative analyses. We demonstrate SEAL’s effectiveness and versatility through three case studies: colorectal cancer tissue analysis with a pharmacologist, melanoma investigation with a cell biologist, and exploration of sky survey data with an astronomer. These studies underscore the importance of integrating image context into embedding spaces when interpreting complex imaging datasets. Implemented as a standalone tool while also integrating seamlessly with computational notebooks, SEAL provides an interactive platform for spatially informed exploration of high-dimensional datasets, significantly enhancing interpretability and insight generation.Competing Interest StatementThe authors have declared no competing interest.National Institutes of Health, https://ror.org/01cwqze88, U01CA284207, R01HD104969}
}
@article{lekschas_hipiler_2018,
	title        = {{HiPiler}: {Visual} {Exploration} of {Large} {Genome} {Interaction} {Matrices} with {Interactive} {Small} {Multiples}},
	shorttitle   = {{HiPiler}},
	author       = {Lekschas, Fritz and Bach, Benjamin and Kerpedjiev, Peter and Gehlenborg, Nils and Pfister, Hanspeter},
	year         = 2018,
	month        = jan,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 24,
	number       = 1,
	pages        = {522--531},
	doi          = {10.1109/TVCG.2017.2745978},
	issn         = {1941-0506},
	url          = {https://ieeexplore.ieee.org/abstract/document/8017587},
	urldate      = {2025-11-12},
	abstract     = {This paper presents an interactive visualization interface-HiPiler-for the exploration and visualization of regions-of-interest in large genome interaction matrices. Genome interaction matrices approximate the physical distance of pairs of regions on the genome to each other and can contain up to 3 million rows and columns with many sparse regions. Regions of interest (ROIs) can be defined, e.g., by sets of adjacent rows and columns, or by specific visual patterns in the matrix. However, traditional matrix aggregation or pan-and-zoom interfaces fail in supporting search, inspection, and comparison of ROIs in such large matrices. In HiPiler, ROIs are first-class objects, represented as thumbnail-like “snippets”. Snippets can be interactively explored and grouped or laid out automatically in scatterplots, or through dimension reduction methods. Snippets are linked to the entire navigable genome interaction matrix through brushing and linking. The design of HiPiler is based on a series of semi-structured interviews with 10 domain experts involved in the analysis and interpretation of genome interaction matrices. We describe six exploration tasks that are crucial for analysis of interaction matrices and demonstrate how HiPiler supports these tasks. We report on a user study with a series of data exploration sessions with domain experts to assess the usability of HiPiler as well as to demonstrate respective findings in the data.},
	keywords     = {Algorithm design and analysis, Bioinformatics, Biomedical Visualization, Data visualization, Genomics, Interactive Small Multiples, Interviews, Matrix Comparison, Visualization}
}
@article{mccurdy_framework_2018,
	title        = {A framework for externalizing implicit error using visualization},
	author       = {McCurdy, Nina and Gerdes, Julie and Meyer, Miriah},
	year         = 2018,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 25,
	number       = 1,
	pages        = {925--935}
}
@article{mccurdy_poemage_2015,
	title        = {Poemage: {Visualizing} the sonic topology of a poem},
	author       = {McCurdy, Nina and Lein, Julie and Coles, Katharine and Meyer, Miriah},
	year         = 2015,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 22,
	number       = 1,
	pages        = {439--448}
}
@article{bladin_globe_2018,
	title        = {Globe {Browsing}: {Contextualized} {Spatio}-{Temporal} {Planetary} {Surface} {Visualization}},
	author       = {Bladin, Karl and Axelsson, Emil and Broberg, Erik and Emmart, Carter and Ljung, Patric and Bock, Alexander and Ynnerman, Anders},
	year         = 2018,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 24,
	number       = 1,
	pages        = {802--811},
	doi          = {10.1109/TVCG.2017.2743958},
	abstract     = {Results of planetary mapping are often shared openly for use in scientific research and mission planning. In its raw format, however, the data is not accessible to non-experts due to the difficulty in grasping the context and the intricate acquisition process. We present work on tailoring and integration of multiple data processing and visualization methods to interactively contextualize geospatial surface data of celestial bodies for use in science communication. As our approach handles dynamic data sources, streamed from online repositories, we are significantly shortening the time between discovery and dissemination of data and results. We describe the image acquisition pipeline, the pre-processing steps to derive a 2.5D terrain, and a chunked level-of-detail, out-of-core rendering approach to enable interactive exploration of global maps and high-resolution digital terrain models. The results are demonstrated for three different celestial bodies. The first case addresses high-resolution map data on the surface of Mars. A second case is showing dynamic processes, such as concurrent weather conditions on Earth that require temporal datasets. As a final example we use data from the New Horizons spacecraft which acquired images during a single flyby of Pluto. We visualize the acquisition process as well as the resulting surface data. Our work has been implemented in the OpenSpace software [8], which enables interactive presentations in a range of environments such as immersive dome theaters, interactive touch tables, and virtual reality headsets.},
	keywords     = {Astronomical visualization, Data visualization, Earth, Mars, Pluto, Rendering (computer graphics), Surface treatment, globe rendering, public dissemination, science communication, space mission visualization}
}
@inproceedings{nagel_toward_2025,
	title        = {Toward a {Design} {Space} for {Embedded} {Urban} {Data} {Visualizations}},
	author       = {Nagel, Till and Huber, Christoph and Eder, Mona},
	year         = 2025,
	booktitle    = {{IEEE} {VIS} 2025 {Short} {Papers}},
	publisher    = {IEEE},
	address      = {Vienna, Austria},
	url          = {https://ieeevis.org/year/2025/program/paper_2bf2b86a-9987-4815-8c2a-8911b3588071.html}
}
@article{bach_time_2016,
	title        = {Time {Curves}: {Folding} {Time} to {Visualize} {Patterns} of {Temporal} {Evolution} in {Data}},
	shorttitle   = {Time {Curves}},
	author       = {Bach, Benjamin and Shi, Conglei and Heulot, Nicolas and Madhyastha, Tara and Grabowski, Tom and Dragicevic, Pierre},
	year         = 2016,
	month        = jan,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 22,
	number       = 1,
	pages        = {559--568},
	doi          = {10.1109/TVCG.2015.2467851},
	issn         = {1941-0506},
	url          = {https://ieeexplore.ieee.org/document/7192639},
	urldate      = {2025-10-30},
	abstract     = {We introduce time curves as a general approach for visualizing patterns of evolution in temporal data. Examples of such patterns include slow and regular progressions, large sudden changes, and reversals to previous states. These patterns can be of interest in a range of domains, such as collaborative document editing, dynamic network analysis, and video analysis. Time curves employ the metaphor of folding a timeline visualization into itself so as to bring similar time points close to each other. This metaphor can be applied to any dataset where a similarity metric between temporal snapshots can be defined, thus it is largely datatype-agnostic. We illustrate how time curves can visually reveal informative patterns in a range of different datasets.},
	keywords     = {Data visualization, Electronic publishing, Encyclopedias, History, Internet, Temporal data visualization, Visualization, information visualization, multidimensional scaling}
}
@misc{yeh_story_2025,
	title        = {Story {Ribbons}: {Reimagining} {Storyline} {Visualizations} with {Large} {Language} {Models}},
	shorttitle   = {Story {Ribbons}},
	author       = {Yeh, Catherine and Menon, Tara and Arya, Robin Singh and He, Helen and Weigel, Moira and Viégas, Fernanda and Wattenberg, Martin},
	year         = 2025,
	month        = aug,
	publisher    = {arXiv},
	doi          = {10.48550/arXiv.2508.06772},
	url          = {http://arxiv.org/abs/2508.06772},
	urldate      = {2025-11-10},
	note         = {arXiv:2508.06772 [cs]},
	abstract     = {Analyzing literature involves tracking interactions between characters, locations, and themes. Visualization has the potential to facilitate the mapping and analysis of these complex relationships, but capturing structured information from unstructured story data remains a challenge. As large language models (LLMs) continue to advance, we see an opportunity to use their text processing and analysis capabilities to augment and reimagine existing storyline visualization techniques. Toward this goal, we introduce an LLM-driven data parsing pipeline that automatically extracts relevant narrative information from novels and scripts. We then apply this pipeline to create STORY RIBBONS, an interactive visualization system that helps novice and expert literary analysts explore detailed character and theme trajectories at multiple narrative levels. Through pipeline evaluations and user studies with STORY RIBBONS on 36 literary works, we demonstrate the potential of LLMs to streamline narrative visualization creation and reveal new insights about familiar stories. We also describe current limitations of AI-based systems, and interaction motifs designed to address these issues.},
	language     = {en},
	keywords     = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning}
}
@misc{khalaila_they_2025,
	title        = {"{They} {Aren}'t {Built} {For} {Me}": {An} {Exploratory} {Study} of {Strategies} for {Measurement} of {Graphical} {Primitives} in {Tactile} {Graphics}},
	shorttitle   = {"{They} {Aren}'t {Built} {For} {Me}"},
	author       = {Khalaila, Areen and Harrison, Lane and Kim, Nam Wook and Cashman, Dylan},
	year         = 2025,
	month        = aug,
	publisher    = {arXiv},
	doi          = {10.48550/arXiv.2508.14289},
	url          = {http://arxiv.org/abs/2508.14289},
	urldate      = {2025-11-10},
	note         = {arXiv:2508.14289 [cs]},
	abstract     = {Advancements in accessibility technologies such as low-cost swell form printers or refreshable tactile displays promise to allow blind or low-vision (BLV) people to analyze data by transforming visual representations directly to tactile representations. However, it is possible that design guidelines derived from experiments on the visual perception system may not be suited for the tactile perception system. We investigate the potential mismatch between familiar visual encodings and tactile perception in an exploratory study into the strategies employed by BLV people to measure common graphical primitives converted to tactile representations. First, we replicate the Cleveland and McGill study on graphical perception using swell form printing with eleven BLV subjects. Then, we present results from a group interview in which we describe the strategies used by our subjects to read four common chart types. While our results suggest that familiar encodings based on visual perception studies can be useful in tactile graphics, our subjects also expressed a desire to use encodings designed explicitly for BLV people. Based on this study, we identify gaps between the perceptual expectations of common charts and the perceptual tools available in tactile perception. Then, we present a set of guidelines for the design of tactile graphics that accounts for these gaps. Supplemental material is available at https://osf.io/3nsfp/?view\_ only=7b7b8dcbae1d4c9a8bb4325053d13d9f.},
	language     = {en},
	keywords     = {Computer Science - Human-Computer Interaction}
}
@article{marai_activity-centered_2018,
	title        = {Activity-{Centered} {Domain} {Characterization} for {Problem}-{Driven} {Scientific} {Visualization}},
	author       = {Marai, G. Elisabeta},
	year         = 2018,
	month        = jan,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 24,
	number       = 1,
	pages        = {913--922},
	doi          = {10.1109/TVCG.2017.2744459},
	issn         = {1941-0506},
	abstract     = {Although visualization design models exist in the literature in the form of higher-level methodological frameworks, these models do not present a clear methodological prescription for the domain characterization step. This work presents a framework and end-to-end model for requirements engineering in problem-driven visualization application design. The framework and model are based on the activity-centered design paradigm, which is an enhancement of human-centered design. The proposed activity-centered approach focuses on user tasks and activities, and allows an explicit link between the requirements engineering process with the abstraction stage-and its evaluation-of existing, higher-level visualization design models. In a departure from existing visualization design models, the resulting model: assigns value to a visualization based on user activities; ranks user tasks before the user data; partitions requirements in activity-related capabilities and nonfunctional characteristics and constraints; and explicitly incorporates the user workflows into the requirements process. A further merit of this model is its explicit integration of functional specifications, a concept this work adapts from the software engineering literature, into the visualization design nested model. A quantitative evaluation using two sets of interdisciplinary projects supports the merits of the activity-centered model. The result is a practical roadmap to the domain characterization step of visualization design for problem-driven data visualization. Following this domain characterization model can help remove a number of pitfalls that have been identified multiple times in the visualization design literature.},
	language     = {eng},
	pmid         = 28866550,
	pmcid        = {PMC5796424},
	keywords     = {Algorithms, Computer Graphics, Humans, Software, User-Computer Interface, Visual Perception}
}
@article{bujack_good_2018,
	title        = {The {Good}, the {Bad}, and the {Ugly}: {A} {Theoretical} {Framework} for the {Assessment} of {Continuous} {Colormaps}},
	author       = {Bujack, Roxana and Turton, Terece L. and Samsel, Francesca and Ware, Colin and Rogers, David H. and Ahrens, James},
	year         = 2018,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 24,
	number       = 1,
	pages        = {923--933},
	doi          = {10.1109/TVCG.2017.2743978},
	keywords     = {Brightness, Color, Image color analysis, Linearity, Sensitivity, Taxonomy, colormap, discriminative power, linearity, monotonicity, order, smoothness, speed, survey, taxonomy, uniformity}
}
@article{he_reframing_2025,
	title        = {Reframing {Pattern}: {A} {Comprehensive} {Approach} to a {Composite} {Visual} {Variable}},
	author       = {He, Tingying and Dykes, Jason and Isenberg, Petra and Isenberg, Tobias},
	year         = 2025,
	journal      = {arXiv preprint arXiv:2508.02639}
}
@inproceedings{dykes_cartographic_1995,
	title        = {Cartographic visualization for spatial analysis},
	author       = {Dykes, Jason A},
	year         = 1995,
	booktitle    = {Proceedings {ICA} / {ACI} - {International} {Cartographic} {Conference}},
	address      = {Barcelona, Catalunya},
	pages        = {1365--1370}
}
@article{willett_perception_2021,
	title        = {Perception! immersion! empowerment! superpowers as inspiration for visualization},
	author       = {Willett, Wesley and Aseniero, Bon Adriel and Carpendale, Sheelagh and Dragicevic, Pierre and Jansen, Yvonne and Oehlberg, Lora and Isenberg, Petra},
	year         = 2021,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 28,
	number       = 1,
	pages        = {22--32},
	doi          = {https://doi.org/10.1109/TVCG.2021.3114844},
	url          = {https://arxiv.org/pdf/2108.03524}
}
@incollection{munzner_process_2008,
	title        = {Process and pitfalls in writing information visualization research papers},
	author       = {Munzner, Tamara},
	year         = 2008,
	booktitle    = {Information visualization: human-centered issues and perspectives},
	publisher    = {Springer},
	pages        = {134--153}
}
@article{munzner_nested_2009,
	title        = {A nested model for visualization design and validation},
	author       = {Munzner, Tamara},
	year         = 2009,
	journal      = {IEEE transactions on visualization and computer graphics},
	volume       = 15,
	number       = 6,
	pages        = {921--928}
}
@article{wood_ballotmaps_2011,
	title        = {{BallotMaps}: {Detecting} name bias in alphabetically ordered ballot papers},
	author       = {Wood, Jo and Badawood, Donia and Dykes, Jason and Slingsby, Aidan},
	year         = 2011,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 17,
	number       = 12,
	pages        = {2384--2391},
	doi          = {https://doi.org/10.1109/TVCG.2011.174},
	url          = {https://openaccess.city.ac.uk/id/eprint/436/1/wood_ballotmaps_2011.pdf}
}
@article{jiang_design_2025,
	title        = {Design {Guidelines} for {Animated} {Data} {Visualization} {Based} on {Perceptual} {Capacity} {Limits}},
	author       = {Jiang, Ouxun and Matuk, Camillia and Gopalakrishnan, Madhumitha and Xu, Wen and Dykes, Jason and Bezerianos, Anastasia and Chevalier, Fanny and Isenberg, Petra and Franconeri, Steven},
	year         = 2025
}
@article{adams_augmented_2023,
	title        = {Augmented {Reality} for {Scholarly} {Publication} of {3D} {Visualizations} in {Astronomy}: {An} {Empirical} {Evaluation}},
	author       = {Adams, Jane L and South, Laura and Çöltekin, Arzu and Goodman, Alyssa and Borkin, Michelle},
	year         = 2023
}
@inproceedings{pahr_investigating_2025,
	title        = {Investigating the {Task} {Load} of {Investigating} the {Task} {Load} in {Visualization} {Studies}},
	author       = {Pahr, Daniel and Di Bartolomeo, Sara},
	year         = 2025,
	booktitle    = {{arXiv} preprint {arXiv}:2509.24643},
	publisher    = {IEEE},
	address      = {Vienna, Austria},
	url          = {https://altvis.github.io/papers/2025/TLX.pdf}
}
@article{field_communicating_2012,
	title        = {Editorial: Communicating Quantities},
	author       = {Field, Kenneth},
	year         = 2012,
	journal      = {The Cartographic Journal},
	publisher    = {Taylor \& Francis},
	volume       = 49,
	number       = 3,
	pages        = {187--194},
	doi          = {10.1179/0008704112Z.00000000034},
	url          = {https://doi.org/10.1179/0008704112Z.00000000034},
	eprint       = {https://doi.org/10.1179/0008704112Z.00000000034}
}
@inproceedings{matejka2017same,
	title        = {Same stats, different graphs: generating datasets with varied appearance and identical statistics through simulated annealing},
	author       = {Matejka, Justin and Fitzmaurice, George},
	year         = 2017,
	booktitle    = {Proceedings of the 2017 CHI conference on human factors in computing systems},
	pages        = {1290--1294}
}
@article{cleveland1993model,
	title        = {A model for studying display methods of statistical graphics},
	author       = {Cleveland, William S},
	year         = 1993,
	journal      = {Journal of Computational and Graphical Statistics},
	publisher    = {Taylor \& Francis},
	volume       = 2,
	number       = 4,
	pages        = {323--343}
}
@inproceedings{munzner2025visualization,
	title        = {Visualization analysis and design},
	author       = {Munzner, Tamara},
	year         = 2025,
	booktitle    = {Proceedings of the Special Interest Group on Computer Graphics and Interactive Techniques Conference Courses},
	pages        = {1--2}
}
@article{maceachren2005visualizing,
	title        = {Visualizing geospatial information uncertainty: What we know and what we need to know},
	author       = {MacEachren, Alan M and Robinson, Anthony and Hopper, Susan and Gardner, Steven and Murray, Robert and Gahegan, Mark and Hetzler, Elisabeth},
	year         = 2005,
	journal      = {Cartography and Geographic Information Science},
	publisher    = {Taylor \& Francis},
	volume       = 32,
	number       = 3,
	pages        = {139--160}
}
@article{maceachren2012visual,
	title        = {Visual semiotics \& uncertainty visualization: An empirical study},
	author       = {MacEachren, Alan M and Roth, Robert E and O'Brien, James and Li, Bonan and Swingley, Derek and Gahegan, Mark},
	year         = 2012,
	journal      = {IEEE transactions on visualization and computer graphics},
	publisher    = {IEEE},
	volume       = 18,
	number       = 12,
	pages        = {2496--2505}
}
@inproceedings{heer2010crowdsourcing,
	title        = {Crowdsourcing graphical perception: using mechanical turk to assess visualization design},
	author       = {Heer, Jeffrey and Bostock, Michael},
	year         = 2010,
	booktitle    = {Proceedings of the SIGCHI conference on human factors in computing systems},
	pages        = {203--212}
}
@book{wexler2017big,
	title        = {The big book of dashboards: visualizing your data using real-world business scenarios},
	author       = {Wexler, Steve and Shaffer, Jeffrey and Cotgreave, Andy},
	year         = 2017,
	publisher    = {John Wiley \& Sons}
}
@article{roth2017visual,
	title        = {Visual variables},
	author       = {Roth, Robert E},
	year         = 2017,
	journal      = {International encyclopedia of geography: People, the earth, environment and technology},
	publisher    = {John Wiley \& Sons, Ltd},
	pages        = {1--11}
}
